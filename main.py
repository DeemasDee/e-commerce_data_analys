# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tWG7XfzSbR9LJSmzKS1y_olrTQPBfq12
"""
!pip install ipython
# Libraries

import pandas as pd
from IPython.display import display
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import seaborn as sns
import folium
from folium.plugins import HeatMap
from geopy.geocoders import Nominatim
import matplotlib.ticker as ticker
from statsmodels.tsa.stattools import adfuller
import display
import streamlit as st


# Set page title
st.title('E-Commerce Data Analysis')

# Available datasets
datasets = [
    "customers_dataset.csv",
    "geolocation_dataset.csv",
    "order_items_dataset.csv",
    "order_payments_dataset.csv",
    "order_reviews_dataset.csv",
    "orders_dataset.csv",
    "products_dataset.csv",
    "sellers_dataset.csv",
    "product_category_name_translation.csv"
]

#  Printig informations
for dataset in datasets:
    #print(f"\n\nDataset: {dataset}")

    #df = pd.read_csv(dataset)

    # Display
    #display(df.head(10))

    # List columns
    #print("\nKolom:", df.columns.tolist())


    df = pd.read_csv(dataset)
    st.write(df.head(10))
    st.write("Kolom:", df.columns.tolist())
    st.write("---")

"""**General Data Pre-processing**"""

# Reading the datasets
customers = pd.read_csv("customers_dataset.csv")
orders = pd.read_csv("orders_dataset.csv")
order_items = pd.read_csv("order_items_dataset.csv")
order_payments = pd.read_csv("order_payments_dataset.csv")
order_reviews = pd.read_csv("order_reviews_dataset.csv")
sellers = pd.read_csv("sellers_dataset.csv")

# Merging the datasets
merged_data = (
    order_items
    .merge(order_payments, on='order_id', how='left')
    .merge(order_reviews, on='order_id', how='left')
    .merge(sellers, on='seller_id', how='left')
    .merge(orders[['order_id', 'customer_id']], on='order_id', how='left')  # Adding customer_id to the merged data
    .merge(customers[['customer_id', 'customer_city', 'customer_state']], on='customer_id', how='left')  # Adding customer_city and customer_state
)

# Columns to be dropped
columns_to_drop = [
    'order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date',
    'payment_sequential', 'payment_installments', 'review_comment_title',
    'review_creation_date', 'review_answer_timestamp', 'seller_zip_code_prefix', 'review_id', 'customer_id'
]

# Drop the columns
merged_data = merged_data.drop(columns=columns_to_drop)

# Display the first 15 rows of the updated merged_data dataset
from IPython.display import display
display(merged_data.head(15))

"""**Review Scores Analysis**
Let's visualize the distribution of review scores in the merged_data dataset. After cleaning the data to exclude missing review scores, we need to count the occurrences of each score and displays the results as a bar plot.

To analyze:

1. Review Distribution: Examine the height of each bar. The taller the bar, the more frequently that score was given by customers.
2. Common Scores: Bars that are notably taller signify scores that are more common. For instance, if the bar for score "5" is the tallest, most reviews are positive.
3. Areas of Improvement: If lower scores (e.g., 1 or 2) have significant counts, it indicates areas where the service or product might be lacking and needs attention.
4. Overall Satisfaction: An overall view can give a sense of customer satisfaction. A skewed distribution towards higher scores means general contentment.

"""

# Remove rows with NaN in the 'review_score' column
merged_data_clean = merged_data.dropna(subset=['review_score'])

# Count the number of occurrences of each review score
score_counts = merged_data_clean['review_score'].value_counts().sort_index()

# Plotting
plt.figure(figsize=(10, 6))
sns.barplot(x=score_counts.index, y=score_counts.values, alpha=0.8, palette='viridis')
plt.title('Number of Reviews by Score')
plt.ylabel('Number of Reviews', fontsize=12)
plt.xlabel('Review Score', fontsize=12)
plt.grid()
plt.show()

# Reading the datasets again
customers = pd.read_csv("customers_dataset.csv")
orders = pd.read_csv("orders_dataset.csv")
order_items = pd.read_csv("order_items_dataset.csv")
order_payments = pd.read_csv("order_payments_dataset.csv")
order_reviews = pd.read_csv("order_reviews_dataset.csv")
sellers = pd.read_csv("sellers_dataset.csv")

# Merging the datasets
merged_data = (
    order_items
    .merge(order_payments, on='order_id', how='left')
    .merge(order_reviews, on='order_id', how='left')
    .merge(sellers, on='seller_id', how='left')
    .merge(orders[['order_id', 'customer_id']], on='order_id', how='left')  # Adding customer_id to the merged data
    .merge(customers[['customer_id', 'customer_city', 'customer_state']], on='customer_id', how='left')  # Adding customer_city and customer_state
)

# Columns to be dropped
columns_to_drop = [
    'order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date',
    'payment_sequential', 'payment_installments', 'review_comment_title',
    'review_creation_date', 'review_answer_timestamp', 'seller_zip_code_prefix', 'review_id', 'customer_id','review_score','review_comment_message'
]

# Drop the columns
merged_data = merged_data.drop(columns=columns_to_drop)

# Display the first 15 rows of the updated merged_data dataset
from IPython.display import display
display(merged_data.head(15))

"""**Payment Type Visualization**

From this plot, businesses can understand customer payment preferences, potentially optimizing operations or sales strategies based on preferred payment methods.

1. Popular Payment Methods: Observe which bars are tallest. This indicates which payment methods are most commonly used by customers.
2. Less Common Methods: Shorter bars represent less frequently used payment methods. These might be areas where you could potentially increase marketing or offer incentives to boost usage if desired.
3. Strategic Decisions: If a less popular method is costly for the business to maintain, it may warrant reconsideration.
"""

# Payment Type Analysis
payment_type_counts = merged_data['payment_type'].value_counts()

# Plotting
plt.figure(figsize=(10, 6))
sns.barplot(x=payment_type_counts.index, y=payment_type_counts.values, palette='viridis')
plt.title('Sales by Payment Type')
plt.ylabel('Number of Sales', fontsize=12)
plt.xlabel('Payment Type', fontsize=12)
plt.grid()
plt.xticks(rotation=45)
plt.show()

"""**Customer Local Visualization**"""

# Load the olist_geolocation_dataset.csv
geolocation_data = pd.read_csv("geolocation_dataset.csv")

sample_geo_data = geolocation_data.sample(frac=0.05)

# Fetch the coordinates
coords = sample_geo_data[['geolocation_lat', 'geolocation_lng']].values.tolist()

# Create a map centered on Brazil
m = folium.Map(location=[-14.2350, -51.9253], zoom_start=4)

# Add the heatmap layer
HeatMap(coords, radius=10).add_to(m)

# Display the map
m

"""**Shipment Data Visual**

showcases shipping routes from sellers to customers, using a sample of 500 transactions from the merged dataset.
"""

# Shipment Analysis

# Sample the merged data for the sake of visualization
sample_merged = merged_data.sample(500)

# Create a new map centered on Brazil
m = folium.Map(location=[-14.2350, -51.9253], zoom_start=4)

# For each row in our sample data, draw a line from the seller to the customer
for index, row in sample_merged.iterrows():
    # Fetch seller coordinates
    seller_coords = geolocation_data[geolocation_data['geolocation_city'] == row['seller_city']][['geolocation_lat', 'geolocation_lng']].mean().values.tolist()
    # Fetch customer coordinates
    customer_coords = geolocation_data[geolocation_data['geolocation_city'] == row['customer_city']][['geolocation_lat', 'geolocation_lng']].mean().values.tolist()

    # Check if both seller and customer coordinates are valid (not NaN)
    if not any(pd.isna(seller_coords)) and not any(pd.isna(customer_coords)):
        # Create a line connecting seller and customer
        folium.PolyLine([seller_coords, customer_coords], color="Red", weight=0.5, opacity=0.5).add_to(m)

# Display the map
m

"""**Sales Revenue Data**"""

# Load datasets
products = pd.read_csv("products_dataset.csv")
category_translation = pd.read_csv("product_category_name_translation.csv")

# Merge data
merged_products = pd.merge(products, category_translation, on='product_category_name', how='left')

# Drop the Portuguese category names
merged_products.drop(columns='product_category_name', inplace=True)

# Count occurrences of each category
category_counts = merged_products['product_category_name_english'].value_counts()

# Plot
plt.figure(figsize=(15,15))
sns.barplot(y=category_counts.index, x=category_counts.values, palette="viridis")
plt.xlabel('Number of Sales', fontsize=12)
plt.ylabel('Product Category', fontsize=12)
plt.title('Distribution of Product Types', fontsize=15)
plt.show()

"""**Revenue By Product Category**"""

# Revenue by Category Analysis

#Load Dataframes
products_df = pd.read_csv("products_dataset.csv")
translations_df = pd.read_csv("product_category_name_translation.csv")
order_items_df = pd.read_csv("order_items_dataset.csv")

# Merge datasets
merged_products = pd.merge(order_items_df, products_df, on="product_id", how="left")
merged_products = pd.merge(merged_products, translations_df, on="product_category_name", how="left")

# Group by product category (in English) and sum the prices
revenue_by_category = merged_products.groupby("product_category_name_english")["price"].sum().sort_values(ascending=False)

# Plot
plt.figure(figsize=(15, 15))
sns.barplot(y=revenue_by_category.index, x=revenue_by_category.values, palette="viridis")
plt.title('Revenue by Product Category')
plt.xlabel('Total Revenue (in R$)')
plt.ylabel('Product Category')

# Adjust x-tick labels
ticks = plt.xticks()[0]
labels = [f"{int(tick/1000)}k" for tick in ticks]
plt.xticks(ticks, labels)

plt.tight_layout()
plt.show()

orders_df = pd.read_csv('orders_dataset.csv')

# Merge order_items with orders to get the customer_id for each order_id
merged_with_orders = pd.merge(order_items, orders_df, on='order_id', how='inner')

# Merge the above result with the customers DataFrame using customer_id
final_merged_data = pd.merge(merged_with_orders, customers, on='customer_id', how='inner')

# Calculate total revenue by state
revenue_by_state = final_merged_data.groupby('customer_state')['price'].sum().sort_values(ascending=False)

# Plot
plt.figure(figsize=(14,7))
revenue_by_state.plot(kind='bar', color='skyblue')

plt.title('Total Revenue by State')
plt.ylabel('Revenue (in R$)')
plt.xlabel('State')

# Adjust the y-axis ticks to display in terms of hundreds of thousands
formatter = ticker.FuncFormatter(lambda x, pos: '{:,.0f}K'.format(x/1000))
plt.gca().yaxis.set_major_formatter(formatter)

plt.tight_layout()
plt.show()

# Calculate the total revenue
total_revenue = merged_data['price'].sum()

# Calculate the total freight cost
total_freight_cost = merged_data['freight_value'].sum()

# Print the results
print(f"Total Revenue: R${total_revenue:,.2f}")
print(f"Total Freight Cost: R${total_freight_cost:,.2f}")

"""**Review Score x Delivery Time Correlation Analysis**"""

# Load datasets
orders_data = pd.read_csv('orders_dataset.csv')
reviews_data = pd.read_csv('order_reviews_dataset.csv')

# Merge the datasets
merged_data = pd.merge(orders_data, reviews_data, on='order_id', how='inner')

# Filter orders with status 'delivered'
delivered_orders = orders[orders['order_status'] == 'delivered'].copy()

# Convert date columns to datetime format
delivered_orders['order_approved_at'] = pd.to_datetime(delivered_orders['order_approved_at'])
delivered_orders['order_delivered_customer_date'] = pd.to_datetime(delivered_orders['order_delivered_customer_date'])

# Calculate the delivery duration in days
delivered_orders['delivery_duration'] = (delivered_orders['order_delivered_customer_date'] - delivered_orders['order_approved_at']).dt.days

# Assuming you've read the olist_order_reviews_dataset.csv into a DataFrame named reviews
merged_data = delivered_orders.merge(reviews_data[['order_id', 'review_score']], on='order_id', how='inner')

# Compute correlation
correlation = merged_data['delivery_duration'].corr(merged_data['review_score'])

print(f"Correlation between delivery time and customer reviews: {correlation:.2f}")

"""**Avarage Delivery Time by Customer's State Visualization**

From the "Average Delivery Time by State" bar chart, we can discern several insights about the distribution of delivery durations across different states:

1. Variability in Delivery Time: The delivery time varies significantly across states. Some states experience notably longer average delivery times, while others benefit from quicker delivery services.

2. Geographic Implications: Typically, states that are farther from distribution centers or main logistic routes may have longer delivery times. This could be due to logistical challenges such as transport availability, road infrastructure, or geographic barriers.

3. Operational Efficiency: Differences in delivery times might also be indicative of the operational efficiency of the sellers or shipping partners catering to particular regions. States with quicker delivery times could be serviced by more efficient or better-equipped sellers and shippers.

4. Customer Experience: States with prolonged delivery durations might have customers who are more prone to dissatisfaction due to the wait. Conversely, states with shorter delivery times could witness higher customer satisfaction rates, as we've seen from the negative correlation between delivery time and review scores.

5. Potential for Business Strategy: For e-commerce businesses, this chart can be invaluable. Recognizing which states have extended delivery durations can inform strategies for improvement. For instance, businesses might consider opening additional distribution centers in states with longer delivery times or partnering with local delivery services to optimize the delivery process.
"""

# Load the dataset
customers_df = pd.read_csv('customers_dataset.csv')

# Now, merge the datasets based on customer_id
merged_df = pd.merge(delivered_orders, customers_df[['customer_id', 'customer_state']], on='customer_id', how='inner')

# Calculate the average delivery duration by state
avg_delivery_by_state = merged_df.groupby('customer_state')['delivery_duration'].mean().sort_values(ascending=False)

# Plotting
plt.figure(figsize=(12, 7))
avg_delivery_by_state.plot(kind='bar', color='skyblue')
plt.title('Average Delivery Time by State')
plt.xlabel('State')
plt.ylabel('Average Delivery Time (days)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""**Customers Analysis**

RFM (Recency, Frequency, Monetary) Analysis
The RFM analysis (Recency, Frequency, Monetary) is a pivotal technique in direct marketing and customer relationship management.

It segments customers based on three criteria: the recency of their last purchase, the frequency of their purchases, and the total amount spent. This segmentation allows businesses to pinpoint their most valuable customers and tailor communication strategies accordingly.

By understanding customer purchasing behavior, companies can optimize resources, enhance retention, and maximize the ROI of their campaigns, ensuring more pertinent offers for each segment.
"""

# Load datasets
customers_df = pd.read_csv('customers_dataset.csv')
order_items_df = pd.read_csv('order_items_dataset.csv')
orders_df = pd.read_csv('orders_dataset.csv')

# Ensure the 'order_approved_at' column is a datetime object
orders_df['order_approved_at'] = pd.to_datetime(orders_df['order_approved_at'])

# Merging the datasets
merged_df = pd.merge(orders_df, order_items_df, on='order_id', how='left')
merged_df = pd.merge(merged_df, customers_df, on='customer_id', how='left')

# Convert order_approved_at to datetime format
merged_df['order_approved_at'] = pd.to_datetime(merged_df['order_approved_at'])

# Get the most recent date in the dataset + 1 day (to use as a reference)
last_date = merged_df['order_approved_at'].max() + pd.Timedelta(days=1)

# Calculate Recency
recency_df = merged_df.groupby('customer_unique_id').agg(last_purchase=('order_approved_at', 'max'))
recency_df['Recency'] = (last_date - recency_df['last_purchase']).dt.days

# Calculate Frequency
frequency_df = merged_df.groupby('customer_unique_id').agg(Frequency=('order_id', 'nunique'))

# Calculate Monetary value
monetary_df = merged_df.groupby('customer_unique_id').agg(Monetary=('price', 'sum'))

# Merge all dataframes together
rfm_df = pd.concat([recency_df, frequency_df, monetary_df], axis=1)

# Drop the last_purchase column as it was an intermediate step to get Recency
rfm_df.drop(columns='last_purchase', inplace=True)

# Define the 'now' point as one day after the latest order in the dataset
now = merged_df['order_approved_at'].max() + pd.Timedelta(days=1)

# Recency: Days since last purchase
recency = merged_df.groupby('customer_unique_id')['order_approved_at'].max().reset_index()
recency.columns = ['customer_unique_id', 'LastPurchaseDate']
recency['Recency'] = (now - recency['LastPurchaseDate']).dt.days

# Frequency: Number of purchases
frequency = merged_df.groupby('customer_unique_id')['order_id'].count().reset_index()
frequency.columns = ['customer_unique_id', 'Frequency']

# Monetary: Total money spent
monetary = merged_df.groupby('customer_unique_id')['price'].sum().reset_index()
monetary.columns = ['customer_unique_id', 'Monetary']

# Merge recency, frequency and monetary dataframes
rfm = pd.merge(recency, frequency, on='customer_unique_id')
rfm = pd.merge(rfm, monetary, on='customer_unique_id')

# Display the top rows
print(rfm.head())
print(rfm.describe())

"""**Histograms Visualization for RFM analysis complemented by a Kernel Density Estimate (KDE) overlay. **

From the plots we can get some insight:

1. Recency Distribution:

a. Insights about how recently most of the customers have made purchases can be drawn.

b. Peaks indicate the most common recency intervals.

c. If a significant peak is towards lower values, it indicates that a substantial portion of customers have purchased recently.

2. Frequency Distribution:

a. Shows the number of times most customers have made purchases.

b. Peaks highlight the most typical purchase frequencies.

c. If most customers have low frequencies, it might indicate a large pool of one-time purchasers. High frequencies signal a group of loyal customers.

3. Monetary Distribution:

a. Represents the total monetary value contributed by customers.

b. Peaks show the most common spending brackets.

c. If the distribution skews towards higher values, it suggests that many customers spend a significant amount.
"""

# Set up the matplotlib figure
f, axes = plt.subplots(3, 1, figsize=(15, 10))

# Plot the distributions
sns.histplot(rfm['Recency'], bins=50, ax=axes[0], kde=True).set_title('Recency Distribution')
sns.histplot(rfm['Frequency'], bins=50, ax=axes[1], kde=True).set_title('Frequency Distribution')
sns.histplot(rfm['Monetary'], bins=50, ax=axes[2], kde=True).set_title('Monetary Distribution')

plt.tight_layout()
plt.show()
